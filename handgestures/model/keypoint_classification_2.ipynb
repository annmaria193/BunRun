{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# specify path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'keypoint_classifier/keypoint.csv'\n",
    "model_save_path = 'model/keypoint_classifier/keypoint_classifier2.keras'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# number of classes set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dataset = np.loadtxt(dataset, delimiter=',', dtype='float32', usecols=list(range(1, (21 * 2) + 1)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dataset = np.loadtxt(dataset, delimiter=',', dtype='int32', usecols=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_dataset, y_dataset, train_size=0.75, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((21 * 2, )),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(20, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">860</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m860\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m210\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)                   │              \u001b[38;5;34m55\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,125</span> (4.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,125\u001b[0m (4.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,125</span> (4.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,125\u001b[0m (4.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()  # tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_save_path, verbose=1, save_weights_only=False)\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(patience=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルコンパイル\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m37/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2489 - loss: 1.6910\n",
      "Epoch 1: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.2687 - loss: 1.6645 - val_accuracy: 0.5988 - val_loss: 1.3527\n",
      "Epoch 2/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5198 - loss: 1.3361\n",
      "Epoch 2: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5258 - loss: 1.3140 - val_accuracy: 0.6249 - val_loss: 1.0396\n",
      "Epoch 3/1000\n",
      "\u001b[1m35/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5669 - loss: 1.0881\n",
      "Epoch 3: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5722 - loss: 1.0740 - val_accuracy: 0.7086 - val_loss: 0.8469\n",
      "Epoch 4/1000\n",
      "\u001b[1m35/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6144 - loss: 0.9402\n",
      "Epoch 4: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6198 - loss: 0.9295 - val_accuracy: 0.7518 - val_loss: 0.7292\n",
      "Epoch 5/1000\n",
      "\u001b[1m37/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6640 - loss: 0.8206\n",
      "Epoch 5: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6621 - loss: 0.8216 - val_accuracy: 0.8215 - val_loss: 0.6457\n",
      "Epoch 6/1000\n",
      "\u001b[1m33/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6848 - loss: 0.7773\n",
      "Epoch 6: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6854 - loss: 0.7743 - val_accuracy: 0.8571 - val_loss: 0.5758\n",
      "Epoch 7/1000\n",
      "\u001b[1m45/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7063 - loss: 0.7135\n",
      "Epoch 7: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7064 - loss: 0.7133 - val_accuracy: 0.8736 - val_loss: 0.5253\n",
      "Epoch 8/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7272 - loss: 0.6671\n",
      "Epoch 8: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7270 - loss: 0.6677 - val_accuracy: 0.8902 - val_loss: 0.4751\n",
      "Epoch 9/1000\n",
      "\u001b[1m35/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7248 - loss: 0.6661\n",
      "Epoch 9: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7272 - loss: 0.6621 - val_accuracy: 0.9017 - val_loss: 0.4382\n",
      "Epoch 10/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7455 - loss: 0.6316\n",
      "Epoch 10: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7491 - loss: 0.6252 - val_accuracy: 0.9087 - val_loss: 0.4043\n",
      "Epoch 11/1000\n",
      "\u001b[1m29/47\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7647 - loss: 0.6126\n",
      "Epoch 11: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7679 - loss: 0.6013 - val_accuracy: 0.9188 - val_loss: 0.3711\n",
      "Epoch 12/1000\n",
      "\u001b[1m39/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7824 - loss: 0.5713\n",
      "Epoch 12: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7825 - loss: 0.5706 - val_accuracy: 0.9238 - val_loss: 0.3544\n",
      "Epoch 13/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7964 - loss: 0.5215 \n",
      "Epoch 13: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7945 - loss: 0.5293 - val_accuracy: 0.9313 - val_loss: 0.3387\n",
      "Epoch 14/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8045 - loss: 0.5378\n",
      "Epoch 14: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8026 - loss: 0.5388 - val_accuracy: 0.9328 - val_loss: 0.3162\n",
      "Epoch 15/1000\n",
      "\u001b[1m40/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8025 - loss: 0.5370\n",
      "Epoch 15: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8026 - loss: 0.5364 - val_accuracy: 0.9343 - val_loss: 0.3043\n",
      "Epoch 16/1000\n",
      "\u001b[1m35/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8030 - loss: 0.5181\n",
      "Epoch 16: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8048 - loss: 0.5159 - val_accuracy: 0.9413 - val_loss: 0.2885\n",
      "Epoch 17/1000\n",
      "\u001b[1m37/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8072 - loss: 0.4986\n",
      "Epoch 17: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8083 - loss: 0.4980 - val_accuracy: 0.9413 - val_loss: 0.2764\n",
      "Epoch 18/1000\n",
      "\u001b[1m46/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8127 - loss: 0.4911\n",
      "Epoch 18: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8130 - loss: 0.4909 - val_accuracy: 0.9423 - val_loss: 0.2699\n",
      "Epoch 19/1000\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8115 - loss: 0.5020\n",
      "Epoch 19: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8117 - loss: 0.5016 - val_accuracy: 0.9418 - val_loss: 0.2650\n",
      "Epoch 20/1000\n",
      "\u001b[1m42/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8133 - loss: 0.4871\n",
      "Epoch 20: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8143 - loss: 0.4863 - val_accuracy: 0.9458 - val_loss: 0.2581\n",
      "Epoch 21/1000\n",
      "\u001b[1m32/47\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8365 - loss: 0.4492\n",
      "Epoch 21: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8337 - loss: 0.4519 - val_accuracy: 0.9423 - val_loss: 0.2480\n",
      "Epoch 22/1000\n",
      "\u001b[1m46/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8209 - loss: 0.4661\n",
      "Epoch 22: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8211 - loss: 0.4660 - val_accuracy: 0.9463 - val_loss: 0.2390\n",
      "Epoch 23/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8374 - loss: 0.4457\n",
      "Epoch 23: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8368 - loss: 0.4466 - val_accuracy: 0.9473 - val_loss: 0.2349\n",
      "Epoch 24/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8428 - loss: 0.4373\n",
      "Epoch 24: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8429 - loss: 0.4349 - val_accuracy: 0.9468 - val_loss: 0.2252\n",
      "Epoch 25/1000\n",
      "\u001b[1m37/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8459 - loss: 0.4310\n",
      "Epoch 25: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8460 - loss: 0.4318 - val_accuracy: 0.9483 - val_loss: 0.2169\n",
      "Epoch 26/1000\n",
      "\u001b[1m32/47\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8552 - loss: 0.4250\n",
      "Epoch 26: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8531 - loss: 0.4242 - val_accuracy: 0.9478 - val_loss: 0.2179\n",
      "Epoch 27/1000\n",
      "\u001b[1m46/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8350 - loss: 0.4419\n",
      "Epoch 27: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8352 - loss: 0.4415 - val_accuracy: 0.9473 - val_loss: 0.2146\n",
      "Epoch 28/1000\n",
      "\u001b[1m40/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8570 - loss: 0.4093\n",
      "Epoch 28: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8553 - loss: 0.4113 - val_accuracy: 0.9493 - val_loss: 0.2076\n",
      "Epoch 29/1000\n",
      "\u001b[1m38/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8483 - loss: 0.4166\n",
      "Epoch 29: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8482 - loss: 0.4168 - val_accuracy: 0.9493 - val_loss: 0.2004\n",
      "Epoch 30/1000\n",
      "\u001b[1m42/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8531 - loss: 0.4046\n",
      "Epoch 30: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8524 - loss: 0.4066 - val_accuracy: 0.9488 - val_loss: 0.2022\n",
      "Epoch 31/1000\n",
      "\u001b[1m38/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8469 - loss: 0.4120\n",
      "Epoch 31: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8473 - loss: 0.4125 - val_accuracy: 0.9493 - val_loss: 0.2019\n",
      "Epoch 32/1000\n",
      "\u001b[1m33/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8419 - loss: 0.4125\n",
      "Epoch 32: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8440 - loss: 0.4124 - val_accuracy: 0.9519 - val_loss: 0.1990\n",
      "Epoch 33/1000\n",
      "\u001b[1m33/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8711 - loss: 0.3975\n",
      "Epoch 33: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8689 - loss: 0.3964 - val_accuracy: 0.9504 - val_loss: 0.1936\n",
      "Epoch 34/1000\n",
      "\u001b[1m36/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8608 - loss: 0.3912\n",
      "Epoch 34: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8602 - loss: 0.3934 - val_accuracy: 0.9498 - val_loss: 0.1925\n",
      "Epoch 35/1000\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8547 - loss: 0.4043\n",
      "Epoch 35: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8548 - loss: 0.4042 - val_accuracy: 0.9493 - val_loss: 0.1831\n",
      "Epoch 36/1000\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8630 - loss: 0.3829\n",
      "Epoch 36: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8629 - loss: 0.3831 - val_accuracy: 0.9529 - val_loss: 0.1838\n",
      "Epoch 37/1000\n",
      "\u001b[1m36/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8637 - loss: 0.3768\n",
      "Epoch 37: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8630 - loss: 0.3784 - val_accuracy: 0.9498 - val_loss: 0.1843\n",
      "Epoch 38/1000\n",
      "\u001b[1m32/47\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8614 - loss: 0.3983\n",
      "Epoch 38: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8614 - loss: 0.3976 - val_accuracy: 0.9509 - val_loss: 0.1893\n",
      "Epoch 39/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8518 - loss: 0.3898\n",
      "Epoch 39: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8518 - loss: 0.3909 - val_accuracy: 0.9509 - val_loss: 0.1788\n",
      "Epoch 40/1000\n",
      "\u001b[1m40/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8501 - loss: 0.4087\n",
      "Epoch 40: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8511 - loss: 0.4074 - val_accuracy: 0.9544 - val_loss: 0.1821\n",
      "Epoch 41/1000\n",
      "\u001b[1m39/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8717 - loss: 0.3648\n",
      "Epoch 41: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8706 - loss: 0.3661 - val_accuracy: 0.9519 - val_loss: 0.1719\n",
      "Epoch 42/1000\n",
      "\u001b[1m32/47\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8619 - loss: 0.3736\n",
      "Epoch 42: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8649 - loss: 0.3704 - val_accuracy: 0.9519 - val_loss: 0.1737\n",
      "Epoch 43/1000\n",
      "\u001b[1m33/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8570 - loss: 0.3838\n",
      "Epoch 43: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8586 - loss: 0.3798 - val_accuracy: 0.9539 - val_loss: 0.1716\n",
      "Epoch 44/1000\n",
      "\u001b[1m37/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8681 - loss: 0.3702\n",
      "Epoch 44: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8670 - loss: 0.3719 - val_accuracy: 0.9559 - val_loss: 0.1683\n",
      "Epoch 45/1000\n",
      "\u001b[1m38/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8668 - loss: 0.3682\n",
      "Epoch 45: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8670 - loss: 0.3671 - val_accuracy: 0.9534 - val_loss: 0.1669\n",
      "Epoch 46/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8646 - loss: 0.3728\n",
      "Epoch 46: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8649 - loss: 0.3714 - val_accuracy: 0.9534 - val_loss: 0.1691\n",
      "Epoch 47/1000\n",
      "\u001b[1m32/47\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8700 - loss: 0.3766\n",
      "Epoch 47: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8709 - loss: 0.3716 - val_accuracy: 0.9544 - val_loss: 0.1683\n",
      "Epoch 48/1000\n",
      "\u001b[1m45/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8736 - loss: 0.3536\n",
      "Epoch 48: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8733 - loss: 0.3542 - val_accuracy: 0.9544 - val_loss: 0.1672\n",
      "Epoch 49/1000\n",
      "\u001b[1m39/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8855 - loss: 0.3300\n",
      "Epoch 49: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8829 - loss: 0.3356 - val_accuracy: 0.9564 - val_loss: 0.1700\n",
      "Epoch 50/1000\n",
      "\u001b[1m36/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8645 - loss: 0.3750\n",
      "Epoch 50: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8641 - loss: 0.3733 - val_accuracy: 0.9569 - val_loss: 0.1680\n",
      "Epoch 51/1000\n",
      "\u001b[1m36/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8717 - loss: 0.3704\n",
      "Epoch 51: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8719 - loss: 0.3690 - val_accuracy: 0.9559 - val_loss: 0.1642\n",
      "Epoch 52/1000\n",
      "\u001b[1m39/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8751 - loss: 0.3464\n",
      "Epoch 52: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8743 - loss: 0.3482 - val_accuracy: 0.9574 - val_loss: 0.1655\n",
      "Epoch 53/1000\n",
      "\u001b[1m35/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8537 - loss: 0.3783\n",
      "Epoch 53: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8563 - loss: 0.3753 - val_accuracy: 0.9559 - val_loss: 0.1661\n",
      "Epoch 54/1000\n",
      "\u001b[1m39/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8718 - loss: 0.3637\n",
      "Epoch 54: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8730 - loss: 0.3606 - val_accuracy: 0.9559 - val_loss: 0.1644\n",
      "Epoch 55/1000\n",
      "\u001b[1m36/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8637 - loss: 0.3722\n",
      "Epoch 55: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8636 - loss: 0.3711 - val_accuracy: 0.9589 - val_loss: 0.1604\n",
      "Epoch 56/1000\n",
      "\u001b[1m33/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8695 - loss: 0.3515\n",
      "Epoch 56: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8694 - loss: 0.3522 - val_accuracy: 0.9559 - val_loss: 0.1573\n",
      "Epoch 57/1000\n",
      "\u001b[1m39/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8678 - loss: 0.3538\n",
      "Epoch 57: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8682 - loss: 0.3540 - val_accuracy: 0.9574 - val_loss: 0.1575\n",
      "Epoch 58/1000\n",
      "\u001b[1m35/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8813 - loss: 0.3283\n",
      "Epoch 58: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8806 - loss: 0.3300 - val_accuracy: 0.9559 - val_loss: 0.1594\n",
      "Epoch 59/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8767 - loss: 0.3368\n",
      "Epoch 59: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8763 - loss: 0.3388 - val_accuracy: 0.9559 - val_loss: 0.1589\n",
      "Epoch 60/1000\n",
      "\u001b[1m45/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8774 - loss: 0.3333\n",
      "Epoch 60: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8774 - loss: 0.3335 - val_accuracy: 0.9589 - val_loss: 0.1576\n",
      "Epoch 61/1000\n",
      "\u001b[1m33/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8724 - loss: 0.3493\n",
      "Epoch 61: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8745 - loss: 0.3451 - val_accuracy: 0.9574 - val_loss: 0.1575\n",
      "Epoch 62/1000\n",
      "\u001b[1m41/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8851 - loss: 0.3375\n",
      "Epoch 62: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8846 - loss: 0.3372 - val_accuracy: 0.9574 - val_loss: 0.1522\n",
      "Epoch 63/1000\n",
      "\u001b[1m42/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8718 - loss: 0.3421\n",
      "Epoch 63: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8718 - loss: 0.3429 - val_accuracy: 0.9599 - val_loss: 0.1578\n",
      "Epoch 64/1000\n",
      "\u001b[1m35/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8756 - loss: 0.3502\n",
      "Epoch 64: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8746 - loss: 0.3496 - val_accuracy: 0.9564 - val_loss: 0.1545\n",
      "Epoch 65/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8800 - loss: 0.3368\n",
      "Epoch 65: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8783 - loss: 0.3386 - val_accuracy: 0.9589 - val_loss: 0.1574\n",
      "Epoch 66/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8800 - loss: 0.3410\n",
      "Epoch 66: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8799 - loss: 0.3408 - val_accuracy: 0.9559 - val_loss: 0.1602\n",
      "Epoch 67/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8780 - loss: 0.3420\n",
      "Epoch 67: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8801 - loss: 0.3400 - val_accuracy: 0.9564 - val_loss: 0.1548\n",
      "Epoch 68/1000\n",
      "\u001b[1m38/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8828 - loss: 0.3295\n",
      "Epoch 68: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8814 - loss: 0.3328 - val_accuracy: 0.9589 - val_loss: 0.1560\n",
      "Epoch 69/1000\n",
      "\u001b[1m32/47\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8728 - loss: 0.3428\n",
      "Epoch 69: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8732 - loss: 0.3425 - val_accuracy: 0.9609 - val_loss: 0.1583\n",
      "Epoch 70/1000\n",
      "\u001b[1m36/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8791 - loss: 0.3311\n",
      "Epoch 70: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8796 - loss: 0.3309 - val_accuracy: 0.9589 - val_loss: 0.1562\n",
      "Epoch 71/1000\n",
      "\u001b[1m36/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8608 - loss: 0.3771\n",
      "Epoch 71: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8627 - loss: 0.3727 - val_accuracy: 0.9609 - val_loss: 0.1532\n",
      "Epoch 72/1000\n",
      "\u001b[1m33/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8840 - loss: 0.3115\n",
      "Epoch 72: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8828 - loss: 0.3162 - val_accuracy: 0.9614 - val_loss: 0.1507\n",
      "Epoch 73/1000\n",
      "\u001b[1m32/47\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8766 - loss: 0.3285\n",
      "Epoch 73: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8791 - loss: 0.3246 - val_accuracy: 0.9589 - val_loss: 0.1505\n",
      "Epoch 74/1000\n",
      "\u001b[1m39/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8755 - loss: 0.3473\n",
      "Epoch 74: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8770 - loss: 0.3439 - val_accuracy: 0.9589 - val_loss: 0.1547\n",
      "Epoch 75/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8789 - loss: 0.3243\n",
      "Epoch 75: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8791 - loss: 0.3263 - val_accuracy: 0.9599 - val_loss: 0.1502\n",
      "Epoch 76/1000\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8797 - loss: 0.3200\n",
      "Epoch 76: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8797 - loss: 0.3201 - val_accuracy: 0.9604 - val_loss: 0.1503\n",
      "Epoch 77/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8851 - loss: 0.3392\n",
      "Epoch 77: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8840 - loss: 0.3385 - val_accuracy: 0.9609 - val_loss: 0.1498\n",
      "Epoch 78/1000\n",
      "\u001b[1m29/47\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8971 - loss: 0.3142\n",
      "Epoch 78: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8933 - loss: 0.3183 - val_accuracy: 0.9569 - val_loss: 0.1500\n",
      "Epoch 79/1000\n",
      "\u001b[1m36/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8689 - loss: 0.3508\n",
      "Epoch 79: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8711 - loss: 0.3471 - val_accuracy: 0.9589 - val_loss: 0.1530\n",
      "Epoch 80/1000\n",
      "\u001b[1m39/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8763 - loss: 0.3372\n",
      "Epoch 80: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8768 - loss: 0.3366 - val_accuracy: 0.9609 - val_loss: 0.1468\n",
      "Epoch 81/1000\n",
      "\u001b[1m40/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8716 - loss: 0.3382\n",
      "Epoch 81: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8724 - loss: 0.3379 - val_accuracy: 0.9609 - val_loss: 0.1487\n",
      "Epoch 82/1000\n",
      "\u001b[1m42/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8924 - loss: 0.3180\n",
      "Epoch 82: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8921 - loss: 0.3176 - val_accuracy: 0.9619 - val_loss: 0.1480\n",
      "Epoch 83/1000\n",
      "\u001b[1m35/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8853 - loss: 0.3217\n",
      "Epoch 83: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8865 - loss: 0.3196 - val_accuracy: 0.9604 - val_loss: 0.1447\n",
      "Epoch 84/1000\n",
      "\u001b[1m38/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8914 - loss: 0.3228\n",
      "Epoch 84: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8899 - loss: 0.3231 - val_accuracy: 0.9599 - val_loss: 0.1445\n",
      "Epoch 85/1000\n",
      "\u001b[1m31/47\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8793 - loss: 0.3443\n",
      "Epoch 85: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8792 - loss: 0.3400 - val_accuracy: 0.9599 - val_loss: 0.1494\n",
      "Epoch 86/1000\n",
      "\u001b[1m41/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.3133\n",
      "Epoch 86: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8865 - loss: 0.3155 - val_accuracy: 0.9584 - val_loss: 0.1507\n",
      "Epoch 87/1000\n",
      "\u001b[1m36/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8748 - loss: 0.3402\n",
      "Epoch 87: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8773 - loss: 0.3361 - val_accuracy: 0.9604 - val_loss: 0.1470\n",
      "Epoch 88/1000\n",
      "\u001b[1m44/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8900 - loss: 0.3197\n",
      "Epoch 88: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8897 - loss: 0.3203 - val_accuracy: 0.9579 - val_loss: 0.1513\n",
      "Epoch 89/1000\n",
      "\u001b[1m39/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8904 - loss: 0.3001\n",
      "Epoch 89: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8901 - loss: 0.3026 - val_accuracy: 0.9599 - val_loss: 0.1514\n",
      "Epoch 90/1000\n",
      "\u001b[1m37/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8905 - loss: 0.3038\n",
      "Epoch 90: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8892 - loss: 0.3077 - val_accuracy: 0.9609 - val_loss: 0.1500\n",
      "Epoch 91/1000\n",
      "\u001b[1m36/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8835 - loss: 0.3264\n",
      "Epoch 91: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8830 - loss: 0.3254 - val_accuracy: 0.9569 - val_loss: 0.1482\n",
      "Epoch 92/1000\n",
      "\u001b[1m37/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8818 - loss: 0.3231\n",
      "Epoch 92: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8817 - loss: 0.3239 - val_accuracy: 0.9589 - val_loss: 0.1458\n",
      "Epoch 93/1000\n",
      "\u001b[1m43/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8737 - loss: 0.3370\n",
      "Epoch 93: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8742 - loss: 0.3357 - val_accuracy: 0.9554 - val_loss: 0.1471\n",
      "Epoch 94/1000\n",
      "\u001b[1m36/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8912 - loss: 0.3114\n",
      "Epoch 94: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8911 - loss: 0.3115 - val_accuracy: 0.9584 - val_loss: 0.1448\n",
      "Epoch 95/1000\n",
      "\u001b[1m38/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8840 - loss: 0.3211\n",
      "Epoch 95: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8848 - loss: 0.3202 - val_accuracy: 0.9599 - val_loss: 0.1447\n",
      "Epoch 96/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8778 - loss: 0.3283\n",
      "Epoch 96: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8781 - loss: 0.3269 - val_accuracy: 0.9594 - val_loss: 0.1501\n",
      "Epoch 97/1000\n",
      "\u001b[1m40/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8742 - loss: 0.3267\n",
      "Epoch 97: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8758 - loss: 0.3249 - val_accuracy: 0.9604 - val_loss: 0.1457\n",
      "Epoch 98/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8770 - loss: 0.3442\n",
      "Epoch 98: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8776 - loss: 0.3419 - val_accuracy: 0.9619 - val_loss: 0.1511\n",
      "Epoch 99/1000\n",
      "\u001b[1m38/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8873 - loss: 0.3195\n",
      "Epoch 99: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8870 - loss: 0.3196 - val_accuracy: 0.9614 - val_loss: 0.1513\n",
      "Epoch 100/1000\n",
      "\u001b[1m33/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8927 - loss: 0.3044\n",
      "Epoch 100: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8916 - loss: 0.3076 - val_accuracy: 0.9584 - val_loss: 0.1503\n",
      "Epoch 101/1000\n",
      "\u001b[1m40/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8894 - loss: 0.3121\n",
      "Epoch 101: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8902 - loss: 0.3105 - val_accuracy: 0.9604 - val_loss: 0.1471\n",
      "Epoch 102/1000\n",
      "\u001b[1m44/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8900 - loss: 0.3050\n",
      "Epoch 102: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8898 - loss: 0.3046 - val_accuracy: 0.9584 - val_loss: 0.1423\n",
      "Epoch 103/1000\n",
      "\u001b[1m33/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.3093\n",
      "Epoch 103: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8877 - loss: 0.3104 - val_accuracy: 0.9574 - val_loss: 0.1482\n",
      "Epoch 104/1000\n",
      "\u001b[1m44/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8832 - loss: 0.3314\n",
      "Epoch 104: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8834 - loss: 0.3299 - val_accuracy: 0.9609 - val_loss: 0.1443\n",
      "Epoch 105/1000\n",
      "\u001b[1m33/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8749 - loss: 0.3510\n",
      "Epoch 105: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8770 - loss: 0.3430 - val_accuracy: 0.9584 - val_loss: 0.1465\n",
      "Epoch 106/1000\n",
      "\u001b[1m44/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8904 - loss: 0.3003\n",
      "Epoch 106: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8904 - loss: 0.3004 - val_accuracy: 0.9599 - val_loss: 0.1477\n",
      "Epoch 107/1000\n",
      "\u001b[1m39/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8954 - loss: 0.2925\n",
      "Epoch 107: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8945 - loss: 0.2941 - val_accuracy: 0.9604 - val_loss: 0.1452\n",
      "Epoch 108/1000\n",
      "\u001b[1m39/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 0.3124\n",
      "Epoch 108: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8890 - loss: 0.3130 - val_accuracy: 0.9609 - val_loss: 0.1490\n",
      "Epoch 109/1000\n",
      "\u001b[1m33/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8948 - loss: 0.3015\n",
      "Epoch 109: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8932 - loss: 0.3060 - val_accuracy: 0.9604 - val_loss: 0.1460\n",
      "Epoch 110/1000\n",
      "\u001b[1m36/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8901 - loss: 0.3042\n",
      "Epoch 110: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8902 - loss: 0.3045 - val_accuracy: 0.9604 - val_loss: 0.1489\n",
      "Epoch 111/1000\n",
      "\u001b[1m32/47\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8867 - loss: 0.3082\n",
      "Epoch 111: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8880 - loss: 0.3081 - val_accuracy: 0.9599 - val_loss: 0.1486\n",
      "Epoch 112/1000\n",
      "\u001b[1m45/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8802 - loss: 0.3322\n",
      "Epoch 112: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8802 - loss: 0.3319 - val_accuracy: 0.9599 - val_loss: 0.1489\n",
      "Epoch 113/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8995 - loss: 0.2765\n",
      "Epoch 113: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8973 - loss: 0.2851 - val_accuracy: 0.9619 - val_loss: 0.1481\n",
      "Epoch 114/1000\n",
      "\u001b[1m41/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8979 - loss: 0.2860\n",
      "Epoch 114: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8977 - loss: 0.2874 - val_accuracy: 0.9554 - val_loss: 0.1465\n",
      "Epoch 115/1000\n",
      "\u001b[1m41/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8902 - loss: 0.3221\n",
      "Epoch 115: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8905 - loss: 0.3200 - val_accuracy: 0.9574 - val_loss: 0.1466\n",
      "Epoch 116/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8765 - loss: 0.3295\n",
      "Epoch 116: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8792 - loss: 0.3255 - val_accuracy: 0.9609 - val_loss: 0.1458\n",
      "Epoch 117/1000\n",
      "\u001b[1m46/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8926 - loss: 0.2973\n",
      "Epoch 117: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8927 - loss: 0.2975 - val_accuracy: 0.9584 - val_loss: 0.1456\n",
      "Epoch 118/1000\n",
      "\u001b[1m46/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8871 - loss: 0.3112\n",
      "Epoch 118: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8872 - loss: 0.3111 - val_accuracy: 0.9594 - val_loss: 0.1489\n",
      "Epoch 119/1000\n",
      "\u001b[1m43/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8974 - loss: 0.2956\n",
      "Epoch 119: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8972 - loss: 0.2962 - val_accuracy: 0.9584 - val_loss: 0.1437\n",
      "Epoch 120/1000\n",
      "\u001b[1m36/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8953 - loss: 0.2869\n",
      "Epoch 120: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8933 - loss: 0.2926 - val_accuracy: 0.9589 - val_loss: 0.1506\n",
      "Epoch 121/1000\n",
      "\u001b[1m32/47\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8924 - loss: 0.3001\n",
      "Epoch 121: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8908 - loss: 0.3049 - val_accuracy: 0.9594 - val_loss: 0.1535\n",
      "Epoch 122/1000\n",
      "\u001b[1m40/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8827 - loss: 0.3170\n",
      "Epoch 122: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8833 - loss: 0.3158 - val_accuracy: 0.9614 - val_loss: 0.1416\n",
      "Epoch 123/1000\n",
      "\u001b[1m40/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8969 - loss: 0.2955\n",
      "Epoch 123: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8963 - loss: 0.2966 - val_accuracy: 0.9609 - val_loss: 0.1472\n",
      "Epoch 124/1000\n",
      "\u001b[1m35/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8910 - loss: 0.2999\n",
      "Epoch 124: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8909 - loss: 0.3009 - val_accuracy: 0.9599 - val_loss: 0.1454\n",
      "Epoch 125/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8946 - loss: 0.2917\n",
      "Epoch 125: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8930 - loss: 0.2964 - val_accuracy: 0.9624 - val_loss: 0.1466\n",
      "Epoch 126/1000\n",
      "\u001b[1m46/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8857 - loss: 0.3085\n",
      "Epoch 126: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8859 - loss: 0.3084 - val_accuracy: 0.9599 - val_loss: 0.1464\n",
      "Epoch 127/1000\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8994 - loss: 0.2939\n",
      "Epoch 127: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8993 - loss: 0.2942 - val_accuracy: 0.9619 - val_loss: 0.1445\n",
      "Epoch 128/1000\n",
      "\u001b[1m36/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8976 - loss: 0.2832\n",
      "Epoch 128: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8974 - loss: 0.2837 - val_accuracy: 0.9644 - val_loss: 0.1405\n",
      "Epoch 129/1000\n",
      "\u001b[1m40/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8932 - loss: 0.3020\n",
      "Epoch 129: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8935 - loss: 0.3011 - val_accuracy: 0.9609 - val_loss: 0.1461\n",
      "Epoch 130/1000\n",
      "\u001b[1m35/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8852 - loss: 0.3315\n",
      "Epoch 130: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8862 - loss: 0.3277 - val_accuracy: 0.9584 - val_loss: 0.1492\n",
      "Epoch 131/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8796 - loss: 0.3249\n",
      "Epoch 131: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8821 - loss: 0.3190 - val_accuracy: 0.9639 - val_loss: 0.1453\n",
      "Epoch 132/1000\n",
      "\u001b[1m32/47\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8943 - loss: 0.2894\n",
      "Epoch 132: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8959 - loss: 0.2889 - val_accuracy: 0.9624 - val_loss: 0.1408\n",
      "Epoch 133/1000\n",
      "\u001b[1m33/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8978 - loss: 0.2850\n",
      "Epoch 133: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8964 - loss: 0.2904 - val_accuracy: 0.9599 - val_loss: 0.1429\n",
      "Epoch 134/1000\n",
      "\u001b[1m35/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8919 - loss: 0.3008\n",
      "Epoch 134: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8922 - loss: 0.3004 - val_accuracy: 0.9594 - val_loss: 0.1417\n",
      "Epoch 135/1000\n",
      "\u001b[1m28/47\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8846 - loss: 0.3080\n",
      "Epoch 135: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8882 - loss: 0.3020 - val_accuracy: 0.9589 - val_loss: 0.1439\n",
      "Epoch 136/1000\n",
      "\u001b[1m33/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8980 - loss: 0.2862\n",
      "Epoch 136: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8966 - loss: 0.2901 - val_accuracy: 0.9599 - val_loss: 0.1486\n",
      "Epoch 137/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9051 - loss: 0.2769\n",
      "Epoch 137: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9030 - loss: 0.2800 - val_accuracy: 0.9624 - val_loss: 0.1419\n",
      "Epoch 138/1000\n",
      "\u001b[1m33/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8997 - loss: 0.2851\n",
      "Epoch 138: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8991 - loss: 0.2860 - val_accuracy: 0.9624 - val_loss: 0.1429\n",
      "Epoch 139/1000\n",
      "\u001b[1m35/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8827 - loss: 0.3456\n",
      "Epoch 139: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8844 - loss: 0.3365 - val_accuracy: 0.9599 - val_loss: 0.1475\n",
      "Epoch 140/1000\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8975 - loss: 0.2811\n",
      "Epoch 140: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8974 - loss: 0.2815 - val_accuracy: 0.9624 - val_loss: 0.1427\n",
      "Epoch 141/1000\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8976 - loss: 0.3016\n",
      "Epoch 141: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8975 - loss: 0.3017 - val_accuracy: 0.9624 - val_loss: 0.1467\n",
      "Epoch 142/1000\n",
      "\u001b[1m35/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8876 - loss: 0.3064\n",
      "Epoch 142: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8889 - loss: 0.3031 - val_accuracy: 0.9624 - val_loss: 0.1437\n",
      "Epoch 143/1000\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8911 - loss: 0.2894\n",
      "Epoch 143: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8911 - loss: 0.2894 - val_accuracy: 0.9609 - val_loss: 0.1445\n",
      "Epoch 144/1000\n",
      "\u001b[1m36/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8920 - loss: 0.3090\n",
      "Epoch 144: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8920 - loss: 0.3078 - val_accuracy: 0.9594 - val_loss: 0.1551\n",
      "Epoch 145/1000\n",
      "\u001b[1m43/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8947 - loss: 0.2846\n",
      "Epoch 145: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8950 - loss: 0.2853 - val_accuracy: 0.9594 - val_loss: 0.1485\n",
      "Epoch 146/1000\n",
      "\u001b[1m35/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8918 - loss: 0.3039\n",
      "Epoch 146: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8913 - loss: 0.3043 - val_accuracy: 0.9624 - val_loss: 0.1439\n",
      "Epoch 147/1000\n",
      "\u001b[1m33/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8950 - loss: 0.2937\n",
      "Epoch 147: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8935 - loss: 0.2970 - val_accuracy: 0.9609 - val_loss: 0.1440\n",
      "Epoch 148/1000\n",
      "\u001b[1m39/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8914 - loss: 0.2981\n",
      "Epoch 148: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8923 - loss: 0.2976 - val_accuracy: 0.9624 - val_loss: 0.1400\n",
      "Epoch 149/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9028 - loss: 0.2820\n",
      "Epoch 149: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9016 - loss: 0.2833 - val_accuracy: 0.9624 - val_loss: 0.1382\n",
      "Epoch 150/1000\n",
      "\u001b[1m40/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8948 - loss: 0.2968\n",
      "Epoch 150: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8943 - loss: 0.2977 - val_accuracy: 0.9624 - val_loss: 0.1449\n",
      "Epoch 151/1000\n",
      "\u001b[1m46/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9081 - loss: 0.2719\n",
      "Epoch 151: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9076 - loss: 0.2726 - val_accuracy: 0.9599 - val_loss: 0.1400\n",
      "Epoch 152/1000\n",
      "\u001b[1m38/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8981 - loss: 0.2877\n",
      "Epoch 152: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8981 - loss: 0.2889 - val_accuracy: 0.9624 - val_loss: 0.1429\n",
      "Epoch 153/1000\n",
      "\u001b[1m35/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8899 - loss: 0.3140\n",
      "Epoch 153: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8915 - loss: 0.3085 - val_accuracy: 0.9629 - val_loss: 0.1417\n",
      "Epoch 154/1000\n",
      "\u001b[1m46/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8934 - loss: 0.2992\n",
      "Epoch 154: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8934 - loss: 0.2989 - val_accuracy: 0.9619 - val_loss: 0.1420\n",
      "Epoch 155/1000\n",
      "\u001b[1m35/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8892 - loss: 0.3148\n",
      "Epoch 155: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8903 - loss: 0.3106 - val_accuracy: 0.9619 - val_loss: 0.1443\n",
      "Epoch 156/1000\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9007 - loss: 0.2848\n",
      "Epoch 156: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9006 - loss: 0.2849 - val_accuracy: 0.9614 - val_loss: 0.1443\n",
      "Epoch 157/1000\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8988 - loss: 0.2846\n",
      "Epoch 157: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8988 - loss: 0.2847 - val_accuracy: 0.9574 - val_loss: 0.1443\n",
      "Epoch 158/1000\n",
      "\u001b[1m33/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8973 - loss: 0.2845\n",
      "Epoch 158: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8971 - loss: 0.2860 - val_accuracy: 0.9624 - val_loss: 0.1366\n",
      "Epoch 159/1000\n",
      "\u001b[1m33/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8977 - loss: 0.2936\n",
      "Epoch 159: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8982 - loss: 0.2911 - val_accuracy: 0.9619 - val_loss: 0.1439\n",
      "Epoch 160/1000\n",
      "\u001b[1m33/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8889 - loss: 0.3159\n",
      "Epoch 160: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8900 - loss: 0.3092 - val_accuracy: 0.9619 - val_loss: 0.1428\n",
      "Epoch 161/1000\n",
      "\u001b[1m34/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8973 - loss: 0.2944\n",
      "Epoch 161: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8975 - loss: 0.2933 - val_accuracy: 0.9619 - val_loss: 0.1367\n",
      "Epoch 162/1000\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8894 - loss: 0.3057\n",
      "Epoch 162: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8895 - loss: 0.3055 - val_accuracy: 0.9634 - val_loss: 0.1476\n",
      "Epoch 163/1000\n",
      "\u001b[1m32/47\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9066 - loss: 0.2628\n",
      "Epoch 163: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9054 - loss: 0.2666 - val_accuracy: 0.9624 - val_loss: 0.1406\n",
      "Epoch 164/1000\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8952 - loss: 0.2898\n",
      "Epoch 164: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8951 - loss: 0.2899 - val_accuracy: 0.9604 - val_loss: 0.1471\n",
      "Epoch 165/1000\n",
      "\u001b[1m36/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9030 - loss: 0.2805\n",
      "Epoch 165: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9016 - loss: 0.2828 - val_accuracy: 0.9609 - val_loss: 0.1463\n",
      "Epoch 166/1000\n",
      "\u001b[1m32/47\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9055 - loss: 0.2731\n",
      "Epoch 166: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9027 - loss: 0.2796 - val_accuracy: 0.9604 - val_loss: 0.1469\n",
      "Epoch 167/1000\n",
      "\u001b[1m40/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8967 - loss: 0.2838\n",
      "Epoch 167: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8963 - loss: 0.2855 - val_accuracy: 0.9604 - val_loss: 0.1402\n",
      "Epoch 168/1000\n",
      "\u001b[1m31/47\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8997 - loss: 0.2938\n",
      "Epoch 168: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9010 - loss: 0.2872 - val_accuracy: 0.9629 - val_loss: 0.1409\n",
      "Epoch 169/1000\n",
      "\u001b[1m44/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8997 - loss: 0.2803\n",
      "Epoch 169: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8995 - loss: 0.2809 - val_accuracy: 0.9594 - val_loss: 0.1468\n",
      "Epoch 170/1000\n",
      "\u001b[1m36/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8906 - loss: 0.2926\n",
      "Epoch 170: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8910 - loss: 0.2919 - val_accuracy: 0.9634 - val_loss: 0.1434\n",
      "Epoch 171/1000\n",
      "\u001b[1m32/47\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8942 - loss: 0.2911\n",
      "Epoch 171: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8965 - loss: 0.2878 - val_accuracy: 0.9594 - val_loss: 0.1428\n",
      "Epoch 172/1000\n",
      "\u001b[1m36/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8938 - loss: 0.3059\n",
      "Epoch 172: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8945 - loss: 0.3037 - val_accuracy: 0.9594 - val_loss: 0.1450\n",
      "Epoch 173/1000\n",
      "\u001b[1m32/47\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8978 - loss: 0.2876\n",
      "Epoch 173: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8973 - loss: 0.2886 - val_accuracy: 0.9594 - val_loss: 0.1472\n",
      "Epoch 174/1000\n",
      "\u001b[1m35/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8976 - loss: 0.2825\n",
      "Epoch 174: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8973 - loss: 0.2846 - val_accuracy: 0.9634 - val_loss: 0.1473\n",
      "Epoch 175/1000\n",
      "\u001b[1m36/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8919 - loss: 0.3145\n",
      "Epoch 175: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8932 - loss: 0.3103 - val_accuracy: 0.9589 - val_loss: 0.1552\n",
      "Epoch 176/1000\n",
      "\u001b[1m32/47\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8948 - loss: 0.2949\n",
      "Epoch 176: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8949 - loss: 0.2961 - val_accuracy: 0.9629 - val_loss: 0.1479\n",
      "Epoch 177/1000\n",
      "\u001b[1m32/47\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9002 - loss: 0.2751\n",
      "Epoch 177: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8989 - loss: 0.2799 - val_accuracy: 0.9619 - val_loss: 0.1518\n",
      "Epoch 178/1000\n",
      "\u001b[1m42/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9022 - loss: 0.2669\n",
      "Epoch 178: saving model to model/keypoint_classifier/keypoint_classifier2.keras\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9022 - loss: 0.2674 - val_accuracy: 0.9619 - val_loss: 0.1407\n",
      "Epoch 178: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f3a6703220>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5373 - accuracy: 0.7969\n",
      "Epoch 00109: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4198 - accuracy: 0.8379 - val_loss: 0.1955 - val_accuracy: 0.9659\n",
      "Epoch 110/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3872 - accuracy: 0.8281\n",
      "Epoch 00110: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8505 - val_loss: 0.2020 - val_accuracy: 0.9614\n",
      "Epoch 111/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3474 - accuracy: 0.8828\n",
      "Epoch 00111: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4132 - accuracy: 0.8433 - val_loss: 0.1984 - val_accuracy: 0.9632\n",
      "Epoch 112/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4205 - accuracy: 0.8672\n",
      "Epoch 00112: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.8397 - val_loss: 0.1973 - val_accuracy: 0.9614\n",
      "Epoch 113/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4995 - accuracy: 0.8125\n",
      "Epoch 00113: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8478 - val_loss: 0.1922 - val_accuracy: 0.9650\n",
      "Epoch 114/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3640 - accuracy: 0.8750\n",
      "Epoch 00114: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4072 - accuracy: 0.8430 - val_loss: 0.1868 - val_accuracy: 0.9596\n",
      "Epoch 115/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5042 - accuracy: 0.8203\n",
      "Epoch 00115: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3999 - accuracy: 0.8535 - val_loss: 0.1966 - val_accuracy: 0.9605\n",
      "Epoch 116/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.5355 - accuracy: 0.7422\n",
      "Epoch 00116: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4174 - accuracy: 0.8433 - val_loss: 0.1919 - val_accuracy: 0.9659\n",
      "Epoch 117/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3729 - accuracy: 0.8750\n",
      "Epoch 00117: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8451 - val_loss: 0.1932 - val_accuracy: 0.9578\n",
      "Epoch 118/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3193 - accuracy: 0.8828\n",
      "Epoch 00118: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4260 - accuracy: 0.8379 - val_loss: 0.1865 - val_accuracy: 0.9641\n",
      "Epoch 119/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3852 - accuracy: 0.8438\n",
      "Epoch 00119: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3797 - accuracy: 0.8622 - val_loss: 0.1900 - val_accuracy: 0.9677\n",
      "Epoch 120/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3636 - accuracy: 0.8594\n",
      "Epoch 00120: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4017 - accuracy: 0.8460 - val_loss: 0.1908 - val_accuracy: 0.9659\n",
      "Epoch 121/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4521 - accuracy: 0.8359\n",
      "Epoch 00121: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8538 - val_loss: 0.1935 - val_accuracy: 0.9659\n",
      "Epoch 122/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4849 - accuracy: 0.8203\n",
      "Epoch 00122: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.8457 - val_loss: 0.1937 - val_accuracy: 0.9659\n",
      "Epoch 123/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4021 - accuracy: 0.8516\n",
      "Epoch 00123: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8478 - val_loss: 0.1907 - val_accuracy: 0.9632\n",
      "Epoch 124/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3601 - accuracy: 0.8906\n",
      "Epoch 00124: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3948 - accuracy: 0.8550 - val_loss: 0.1862 - val_accuracy: 0.9605\n",
      "Epoch 125/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.4446 - accuracy: 0.7891\n",
      "Epoch 00125: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8520 - val_loss: 0.1888 - val_accuracy: 0.9623\n",
      "Epoch 126/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3733 - accuracy: 0.8438\n",
      "Epoch 00126: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3913 - accuracy: 0.8550 - val_loss: 0.1937 - val_accuracy: 0.9632\n",
      "Epoch 127/1000\n",
      " 1/27 [>.............................] - ETA: 0s - loss: 0.3000 - accuracy: 0.8828\n",
      "Epoch 00127: saving model to model/keypoint_classifier\\keypoint_classifier.hdf5\n",
      "27/27 [==============================] - 0s 3ms/step - loss: 0.3820 - accuracy: 0.8583 - val_loss: 0.1867 - val_accuracy: 0.9632\n",
      "Epoch 00127: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2314aafaaf0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[cp_callback, es_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9620 - loss: 0.1383 \n"
     ]
    }
   ],
   "source": [
    "# モデル評価\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存したモデルのロード\n",
    "model = tf.keras.models.load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step\n",
      "[1.3086904e-04 9.9695134e-01 6.5547184e-10 2.9178080e-03 9.6915649e-11]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# 推論テスト\n",
    "predict_result = model.predict(np.array([X_test[0]]))\n",
    "print(np.squeeze(predict_result))\n",
    "print(np.argmax(np.squeeze(predict_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from seaborn) (3.10.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.56.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAH5CAYAAACWFaT0AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQbVJREFUeJzt3QucTfX+//H33IwxGIa5kJRSLrlfilwqFKXkJN0kOtJJKETlJCpCKqJcSmV08Us66ZSSxCkKYeQ27pG7GXIdl7n/H2v1n51todnYs+a7vZ6/3/rt2d+19prvrN9qfObz/Xy/KygnJydHAAAABgt2uwMAAADni4AGAAAYj4AGAAAYj4AGAAAYj4AGAAAYj4AGAAAYj4AGAAAYj4AGAAAYL1QFxKGOzd3uQsCK+XS9210ISFGFI93uQsA6cDzV7S4APstM35lv3ytj32a/nTus9BUyERkaAABgvAKToQEAAHmUneV2DwocMjQAAMB4BDQAAJgmJ9t/m4927typBx98UKVKlVJERISqV6+upUuXevZbz8AeOHCgypQpY+9v0aKFNm7c6HWO/fv3q0OHDipevLhKlCihLl26KDXVt1o6AhoAAHBODhw4oEaNGiksLEwzZ87UmjVr9Prrr6tkyZKeY0aMGKExY8ZowoQJ+uWXXxQZGamWLVvqxIkTnmOsYCYpKUmzZ8/WjBkzNG/ePD366KM+9SUoxwqdCgBmOfkPs5z8g1lO/sMsJ5goX2c57V7rt3OHlamS52OfffZZ/fzzz5o/f/5p91shRtmyZfXUU0+pb9++dtuhQ4cUFxenhIQE3XfffVq7dq2qVq2qJUuWqF69evYx3377rW677Tbt2LHD/nxekKEBAMAwOTnZftvS0tJ0+PBhr81qO50vv/zSDkLat2+v2NhY1a5dWxMnTvTs37Jli/bs2WMPM+WKiorSddddp4ULF9rvrVdrmCk3mLFYxwcHB9sZnbwioAEAAB7Dhg2zg46TN6vtdDZv3qzx48frqquu0qxZs9StWzc98cQTmjx5sr3fCmYsVkbmZNb73H3WqxUMnSw0NFTR0dGeY/KCadsAAJgm2/fi3bzq37+/+vTp49UWHh5+2mOzs7PtzMrQoUPt91aGZvXq1Xa9TKdOnZSfyNAAAACv4MWabXTydqaAxpq5ZNW/nKxKlSratm2b/XV8fLz9mpyc7HWM9T53n/WakpLitT8zM9Oe+ZR7TF4Q0AAAYJoCMm27UaNGWr/ee+LJhg0bdNlll9lfV6hQwQ5K5syZ49lv1eRYtTENGza031uvBw8eVGJioueYuXPn2tkfq9YmrxhyAgAA56R37966/vrr7SGne+65R4sXL9Y777xjb5agoCD16tVLQ4YMsetsrADn+eeft2cutW3b1pPRadWqlbp27WoPVWVkZKhHjx72DKi8znCyENAAAGCaAvLog/r162v69Ol23c1LL71kByxvvPGGva5MrqefflpHjx6115WxMjGNGze2p2UXLlzYc8zHH39sBzHNmze3Zze1a9fOXrvGF6xDcxFgHRr/YB0a/2EdGpgoP9ehSd+6zG/nLnRZHZmIDA0AAKY5h0cUBDqKggEAgPHI0AAAYBo/rkNjKgIaAAAMYz2iAN4YcgIAAMYjQwMAgGkYcnIgQwMAAIxHhgYAANNQQ+NAhgYAABiPDA0AAKYpII8+KEjI0AAAAOORoQEAwDTU0DgQ0AAAYBqmbTsw5AQAAIxHhgYAANMw5ORAhgYAABiPDA0AAKahhsaBDA0AADAeGRoAAAyTk8PCeqciQwMAAIxHhgYAANMwy8mBgAYAANNQFOzAkBMAADAeGRoAAEzDkJMDGRoAAGA8MjQAAJgmm2nbpyJDcxrht9+nqA/nqHCHx/9qDAtT4U5PqNi46So+cYaKPDFIQcVLen2ucMfuKvrSeBV/f6aKDnk7/ztuqA3rFyo9bYdjGz16iNtdM0rnLvfrh5+/1Obtifb2zexP1LxFU3tfiZJRGjZigBYu/Vbb9qzQr6v/p6GvPKdixYu63W2jdXuskzZtWKTUw79pwU9fqX69Wm53KWBwbeErAppThFSopELNblfWtt+82q3gJqxWAx1760WlvtxbQSVKq8iTLzg+nz7vW2X88kM+9th81zdqrUvL1/ZsrW69z27/z3++drtrRtm1c4+GvPCaWtxwl1rc2E4/zVukD/5vrCpVrqj4+FjFl4nVoAGvqGnD29Xz8f5q1qKJRr/1stvdNlb79m302quDNHjISNW/rpVWrFyjb77+WDExpdzumvG4tnmsofHXZqignJycHBUAhzo2d7sLUnhhFR38to5PHq3Cd3ZQ1tbfdOLjcVJEpIqP+4+OjRuqzCXz7EODy1yqYiMSlPpCD2X9ttb7NP94SGF1Gyl1wL9UEMR8ul4mee21F3TbbS1UtWpjFWRRhSNV0G34/Re9+Pyr+vjDzxz72rRtpXHvvKrLytRSVlbBSl8fOJ6qgs7KGixZukJP9hpgvw8KCtLvm5do7LhJGvHqWLe7ZzRTr21m+s58+14nFk/z27kLX9teJiJDc5KITk8qc8UiZSUt82oPqXCVgkLDlJmU6GnL3r1d2fuSFXJVVRd6GrjCwsL0wP13aXLCJ253xWjBwcFq2+42FSlSREsW/3raY4oXL6ojR1ILXDBjyn1ap04NzZk739Nm/W04Z+5PatCgrqt9Mx3X1od1aPy1XSxFwfv27dP777+vhQsXas+ePXZbfHy8rr/+enXu3FkxMTF/e460tDR782rLylZ4iHvxVViDmxRyeUWlDjqpbub/C46KVk5GunTsqFd79qED9j5cOHe2aakSJYrrgw/999dHIKtS9WrNnP2JwguH62jqMXXu0F0b1nsPn1qio0uqT7/H9WHCVFf6abrSpaMVGhqqlOR9Xu0pKXtVudKVrvUrEHBt88jgoSF/8SmCWLJkia6++mqNGTNGUVFRatq0qb1ZX1ttlStX1tKlS//2PMOGDbM/c/I2cvXvcktQdIwKP9hdx8YPkzIyXOsHpM4P36dZs/6n3buT3e6KkTZt3KKbmrRVy+b3KOH9/9ObE17R1af8I1C0WKSmTHvbDnRGDHvLtb4CgGsZmp49e6p9+/aaMGGCPaZ5Misl+Nhjj9nHWNmbs+nfv7/69Onj1XbisTvllpAKVys4qqSKDp7gaQsKCVFIpRoqdHNbHR3xjILCCklFIr2yNNZnMg7td6nXgad8+UvUvFkT3XNvV7e7YqyMjAxt2bzN/nrl8iTVqlNdj3Z7SH17DbLbIotGaup/3lVq6lF16tBdmZmZLvfYTPv27bevXWxcaa/22NgY7Une61q/AgHXNo8MHhoqEAHNihUrlJCQ4AhmLFZb7969Vbt27b89T3h4uL2dLMfF4abMpGU60r+LV1tE137K3rVdaV9/ouw/9ionM0OhVesoc+mf47rB8eUUXDpOWRvXuNTrwNPpoXuVkrJP33wzx+2uBFQtTXihQp7MzKefv6f0tHR1vK+b0tLS3e6e0YHjsmUr1eymxvryy1me34HW+3HjJ7ndPaNxbZEvAY1VK7N48WJ7aOl0rH1xcXEyzonjyt5xypBX2gnlpB72tKf/OFMRHbrp2NEjyjl+VBEP9VTmxiSvGU7BsWWlwhEKsupqCoUruPyfqf7snVulLP4SPhvrF9ZDD92jjz76jCLVczRgUB/NmT1PO3bsVtGikWrX/nY1anyt7rmrix3MTJv+viIiIvT4o/1UrFhRe8v9izibv/Z8Nmr0RE16b5QSl63UkiW/6omeXRUZGaGEydQlnS+ubR7w3+z5BTR9+/bVo48+qsTERDVv3twTvCQnJ2vOnDmaOHGiXnvtNQUie/p2Ts6fC+qFhSlz5VJ7evfJIh55SqFV/lr8qdjL79ivh3s/oJx91IScTfPmTXTZZeWUMJnZTeeqdEwpvTXhFcXFx+rw4SNak7TeDmZ+/N8CXd/4WtWr/+e9uWT5916fq1O9mbZvy7/ppoFi2rQvFVM6Wi8M7Kv4+BitWJGk1rc/aGcZcX64tsiXdWimTp2qUaNG2UFN7l/SISEhqlu3rl0Xc88995i7Dk2AMm0dGlOYsA6NqUxYhwZwcx2a4/MS/HbuiKaddVFM27733nvtzRrntKZwW0qXLm2vHQAAAGDUwymtAKZMmTIXtjcAAODvUUPjwNO2AQAwDQvrOfDoAwAAYDwyNAAAmIYhJwcyNAAAwHhkaAAAMA01NA5kaAAAgPHI0AAAYBpqaBzI0AAAAOORoQEAwDTU0DgQ0AAAYBqGnBwYcgIAAMYjQwMAgGnI0DiQoQEAAMYjQwMAgGkoCnYgQwMAAIxHhgYAANNQQ+NAhgYAABiPDA0AAKahhsaBgAYAANMw5OTAkBMAADAeGRoAAEzDkJMDGRoAAGA8MjQAAJiGGhoHMjQAAMB4ZGgAADANGRoHMjQAAMB4BDQAAJgmJ8d/mw9eeOEFBQUFeW2VK1f27D9x4oS6d++uUqVKqWjRomrXrp2Sk5O9zrFt2za1bt1aRYoUUWxsrPr166fMzEz5iiEnAABMU4CGnK655hp9//33nvehoX+FFr1799bXX3+tadOmKSoqSj169NBdd92ln3/+2d6flZVlBzPx8fFasGCBdu/erYceekhhYWEaOnSoT/0goAEAAOfMCmCsgORUhw4d0nvvvacpU6aoWbNmdtukSZNUpUoVLVq0SA0aNNB3332nNWvW2AFRXFycatWqpcGDB+uZZ56xsz+FChXKcz8YcgIAwMQMjZ+2tLQ0HT582Guz2s5k48aNKlu2rK644gp16NDBHkKyJCYmKiMjQy1atPAcaw1HlS9fXgsXLrTfW6/Vq1e3g5lcLVu2tL9nUlKST5eEgAYAAHgMGzbMHh46ebPaTue6665TQkKCvv32W40fP15btmxRkyZNdOTIEe3Zs8fOsJQoUcLrM1bwYu2zWK8nBzO5+3P3+YIhJwAATOPHRx/07z9Affr08WoLDw8/7bG33nqr5+saNWrYAc5ll12mTz/9VBEREcpPZGgAAIBX8FK8eHGv7UwBzamsbMzVV1+tTZs22XU16enpOnjwoNcx1iyn3Job6/XUWU+5709Xl3M2BDQAAJjGjzU05yM1NVW//fabypQpo7p169qzlebMmePZv379ervGpmHDhvZ763XVqlVKSUnxHDN79mw7iKpatapP35shJwAAcE769u2rO+64wx5m2rVrlwYNGqSQkBDdf//9du1Nly5d7OGr6OhoO0jp2bOnHcRYM5wst9xyix24dOzYUSNGjLDrZgYMGGCvXZPXrFAuAhoAAEzj4wJ4/rJjxw47ePnjjz8UExOjxo0b21Oyra8to0aNUnBwsL2gnjVTyprBNG7cOM/nreBnxowZ6tatmx3oREZGqlOnTnrppZd87ktQTk7BuCqHOjZ3uwsBK+bT9W53ISBFFY50uwsB68DxVLe7APgsM31nvn2v45Of9du5IzoNl4nI0AAAYJoCtFJwQUFAAwCAaQhoCm5Aw7CI/xzdOc/tLgSkImWbuN2FgBUcFOR2FwJWSHCI210AAjugAQAA7i+sZyrWoQEAAMYjQwMAgGFysgvEBOUChQwNAAAwHhkaAABMwywnBzI0AADAeGRoAAAwDbOcHAhoAAAwDUXBDgw5AQAA45GhAQDANBQFO5ChAQAAxiNDAwCAacjQOJChAQAAxiNDAwCAaXKY5XQqMjQAAMB4ZGgAADANNTQOBDQAAJiGhfUcGHICAADGI0MDAIBpeJaTAxkaAABgPDI0AACYhhoaBzI0AADAeGRoAAAwTA7Tth3I0AAAAOORoQEAwDTU0DgQ0AAAYBqmbTsw5AQAAIxHhgYAANMw5ORAhgYAABiPDA0AAKZh2rYDGRoAAGA8MjQAAJiGGhoHMjQAAMB4ZGgAADAN69A4ENAAAGAahpwcGHICAADGI0MDAIBheNq2ExkaAABgPDI0AACYhhoaBzI0AADAeAQ0efT8gD5KT9vhta1a+YPb3TJC8t59eubFEWp06z2qe9Od+kfHblq9doNn/+wfflbXXv+291drdKvWbfjNcY60tHQNeX2sfUz9Fv9Qr38P0b79B/L5JzFbv37dlZG+U6+/9qLbXQkIZcvGK2HSGO3etUqHDm7SssTvVadODbe7ZZxGja7VZ5+9p82bF+v48a26445bznjsmDEv28f06PHPfO1jgc3Q+GszFENOPkhKWqdWt97veZ+Zmelqf0xw6PARdXzsKV1bp6YmvD5YJUtEaev2nSperKjnmOMnTqhOjWvUsllTvfDK6NOe55Uxb2vewiUaOeTfKhoZqaEjx9lBzUcTXs/Hn8Zc9erWVNdHHtTKlWvc7kpAKFEiSj/8b7p+/HGB7mjTUfv2/aGKFSvo4MFDbnfNOJGRRbRq1Vp98MGnmjr1nTMe16ZNS117bW3t2rUnX/sHcxDQ+CAzM0vJyXvd7oZR3v94muJjYzTkuT6etnJl472OadOquf26c3fyac9xJPWoPp/xnUa88LSuq1vLbhv8XB+1eeBRrVi9VjWrVfHrzxAI/2BM/uAtPdbtaf27/xNudycg9Ov7uHbs2KWujz7lafv99+2u9slU3333g72dTdmycRo58kXdcUdHTZ8+Kd/6VqCxsJ4DQ04+sP4C+33LUq1b97MmJ7ypSy8t63aXCrz//bRI11S+Sn0GvKymre/T3Z2767MvZ/p0jjXrN9rZsAb1anvarrjsUpWJi9WK1ev80OvA8uaYoZr5zRzNnTvf7a4EjNtvv1mJy1bq/6ZM0I7ty7X4l2/1z38+4Ha3AlJQUJDee+8NjRr1ttau3eh2dwoOhpz8H9Bs375d//zn2cc309LSdPjwYa8tJ6dgX8TFS37VI4/0tv9C6Nnz37r88ks1d87nKlo00u2uFWg7du3R1C++Vvlyl+jtUUN07z9aa9ioCfrvN7PzfI59fxxQWFio1zCVpVR0Ce3bv98PvQ4c99zTRrVrV9NzA4a53ZWAUqFCef3r0Y7atGmLbr+9g95+50ONGvmSOj54t9tdCzhPPdXN/oNm7FgyM8jnIaf9+/dr8uTJev/99894zLBhw/Tii96FicHBxRQSWlwF1axZ//N8vWr1Wi1e/Ks2bVyku+++QwkJn7jat4IsOzvHztD0eqyz/b7K1RW1cfNWffrFN7rztpvd7l5AK1eurEa+/pJuve1++48IXDjBwcFKTFyp5we+Yr9fviJJ11xTSV27dtSHH33mdvcChhWMd+/+sK6/vrXbXSlwcgzOpBSYgObLL7886/7Nmzf/7Tn69++vPn3+qqmwlCptVh3EoUOHtXHjZlW88nK3u1KgxZSK1pWXl/dqu+LyS/X9Dz/n+RylS5VURkamDh9J9crS/LH/oEpHR1/Q/gaSOnWqKy4uxh4OyRUaGqomTRro8cc7K7JoBWWz2ug52b07xTH8sW7dRv2j7W2u9SlQZ0DFxpbWhg0Lve7h4cMH2DOdKldu7Gr/YHhA07ZtW3tM82xDRNb+swkPD7c3Xz5TEAstr7jicn085XO3u1Kg1a5RVb9v2+HVtnXbTpWJj83zOapWusr+JfbL0uW6+aY/f4Ft2bpDu5NTVLNa5Qve50Axd+5PqlW7mVfbuxNHav363/Tqa2MJZs7DwoVLdfXVV3i1XXXVFdp2yr2O8zNlyuf2fXyyr7760G7/4INpuqiRoTn/gKZMmTIaN26c7rzzztPuX758uerWratAY/1F8PXX39u/sMqUidPAgU8pKytLU6d+4XbXCrSO97ZVx389pXcmf6JWzZtq1Zr1dlHwoKef8JravXtPilL2/WG/3/L//1GwMjOlS0WrWNFI3XX7LRrx5kRFFS9mB5NDR423Zzcxw+nMUlOPKilpvVfb0aPH9McfBxzt8M3oMRM178cv9MzTPfTZf2aofr1aeqRLBz3++DNud8041n/PV56U6bbqE2vUqKoDBw5q+/Zd2r//oNfxGRkZ9mxTK0MOnFdAYwUriYmJZwxo/i57Y6pyl5TRhx+8pVKlSmrv3v1asGCxmjRto337KEo9m+pVKumNYc9r9IQETUiYokvKxOuZJ/+l21v+lTn43/xFGjB0pOd9v0HD7ddu/+yg7l0etL9+5ol/2XULvZ4bYv9Cu/7aunq+b3cXfiJASkxcofb3PKIhg/vrued62VO2n+r7gv7vk+lud8041mKE33031fN+xIiB9uuHH07To4/2dbFnBRwZVoegHB+jj/nz5+vo0aNq1arVafdb+5YuXaobbrjBl9OqUHg5n45H3h3dOc/tLgSkImWbuN2FgGXaELRJQoJD3O5CwLJWMc4vR3r4r16r2Fvf6KLI0DRpcvZf4pGRkT4HMwAAwAfU0DiwUjAAAKYhoHFgpWAAAGA8MjQAABgmECffnC8yNAAAwHhkaAAAMA01NA5kaAAAgPHI0AAAYBoyNA5kaAAAgPHI0AAAYJgcMjQOBDQAAJiGgMaBIScAAHDehg8fbj+HrVevXp62EydOqHv37ipVqpSKFi2qdu3aKTk52etz27ZtU+vWrVWkSBHFxsaqX79+yszM9Pn7E9AAAGCabD9u52DJkiV6++23VaNGDa/23r1766uvvtK0adP0448/ateuXbrrrrs8+7OysuxgJj09XQsWLNDkyZOVkJCggQP/fOq6LwhoAACAR1pamg4fPuy1WW1nkpqaqg4dOmjixIkqWbKkp/3QoUN67733NHLkSDVr1kx169bVpEmT7MBl0aJF9jHfffed1qxZo48++ki1atXSrbfeqsGDB2vs2LF2kOMLAhoAAAwsCvbXNmzYMEVFRXltVtuZWENKVpalRYsWXu2JiYnKyMjwaq9cubLKly+vhQsX2u+t1+rVqysuLs5zTMuWLe0gKikpyadrQlEwAADw6N+/v/r06fNXg6Tw8HCdzieffKJly5bZQ06n2rNnjwoVKqQSJUp4tVvBi7Uv95iTg5nc/bn7fEFAAwCAafw4yyk8PPyMAczJtm/frieffFKzZ89W4cKF5TaGnAAAgM+sIaWUlBTVqVNHoaGh9mYV/o4ZM8b+2sq0WHUwBw8e9PqcNcspPj7e/tp6PXXWU+773GPyioAGAADTFIBZTs2bN9eqVau0fPlyz1avXj27QDj367CwMM2ZM8fzmfXr19vTtBs2bGi/t16tc1iBUS4r41O8eHFVrVrVp0vCkBMAAPBZsWLFVK1aNa+2yMhIe82Z3PYuXbrY9TjR0dF2kNKzZ087iGnQoIG9/5ZbbrEDl44dO2rEiBF23cyAAQPsQuO8DHudjIAGAADDmPLog1GjRik4ONheUM+a+m3NYBo3bpxnf0hIiGbMmKFu3brZgY4VEHXq1EkvvfSSz98rKCcnp0BclULh5dzuQsA6unOe210ISEXKNnG7CwHLWm0U/hESHOJ2FwLW8eNb8+17HWh3o9/OXfI/P8hE1NAAAADjMeQEAIBhTBlyyk9kaAAAgPHI0AAAYJpzfIhkICNDAwAAjEeGBgAAw+SQoXEgQwMAAIxHhgYAANOQoXEgoAEAwDAMOTkx5AQAAIxHhgYAANOQoXEgQwMAAIxHhgYAAMNQQ+NEhgYAABiPDA0AAIYhQ+NEhgYAABiPDA0AAIYhQ+NEQAMAgGlygtzuQYFTYAKa7Jwct7sQsCLKNnG7CwHp+5LXu92FgNXiwAK3uxCwsrMy3e4CENgBDQAAyBuGnJwoCgYAAMYjQwMAgGFysqmhORUZGgAAYDwyNAAAGIYaGicyNAAAwHhkaAAAMEwO69A4ENAAAGAYhpycGHICAADGI0MDAIBhmLbtRIYGAAAYjwwNAACG4fGHTmRoAACA8cjQAABgGGponMjQAAAA45GhAQDAMGRonAhoAAAwDEXBTgw5AQAA45GhAQDAMAw5OZGhAQAAxiNDAwCAYXjathMZGgAAYDwyNAAAGCYn2+0eFDxkaAAAgPHI0AAAYJhsamgcCGgAADAMRcFODDkBAADjkaEBAMAwLKznRIYGAAAYjwwNAACG4eGUTmRoAACA8cjQAABgGGponMjQAAAA45GhAQDAMCys50RAAwCAYVhYz4khJwAAYDwyNAAAGIZp205kaAAAgPHI0AAAYBiKgp3I0AAAAOMR0Pio22OdtGnDIqUe/k0LfvpK9evVcrtLAYHr6pvyT7RVnW+HqfFvH+j6pHdVLaGfIq4s63VMoZgSqvxWT12/aqKabPlQdWe/otKtr/M6JuKKMqo2+Wk1WvOeGm+arNpfDlaJRtfk809jLu5b/+Ha/v0sJ39tpiKg8UH79m302quDNHjISNW/rpVWrFyjb77+WDExpdzumtG4rr4r0fAa7Zo0S8tu+7dWtB+soNBQ1Zw6QMFFwj3HVH6rh4pULKtVD72iJTc+pX3f/KJrJvZR0WqXe46p/tGzCgoJ0fK7X1Tizc8oNel3u80KhnB23Lf+w7XFuSCg8UHvJ7vq3femaPIHn2rt2o16vPuzOnbsuB7ufJ/bXTMa19V3K+9/WXum/qBj63fo6JqtWvfkWBW+NEbFalzhOSaqfiXtfHemjvy6SSe2pmjrqM+VeeioitX885iw6GIqcmVZbXtzuo6u2abjW/Zo85CPFVKksCKrXOriT2cG7lv/4drmbZaTvzZTEdDkUVhYmOrUqaE5c+d72nJycjRn7k9q0KCuq30zGdf1wggtVsR+zTyY6mk7tGS9Ytter9ASRaWgIPvr4MJhOvjzGnt/xv4jOrZxp+LuucHO7ASFBKvsQzcrfe9BHVmx2bWfxQTct/7Dtc17UbC/totmltPx48eVmJio6OhoVa1a1WvfiRMn9Omnn+qhhx466znS0tLs7WTWDRsUVHAvZOnS0QoNDVVK8j6v9pSUvapc6UrX+mU6rusFEBSkikM669Av63R03XZP85quI1X1nd5qvH6SsjMylX08Xas7v6rjv+/xHLOi/UuqlvC0mvz2gfUbUun7DmnlfS/bmRycGfet/3BtkS8Zmg0bNqhKlSpq2rSpqlevrhtuuEG7d+/27D906JAefvjhvz3PsGHDFBUV5bXlZB85t58AuMhdNfwRRVa6VGv+Ncqr/fJn71NoVOSf9TG3PKvtE76ya2giq5T3+qwVxPzaZqASW/XXvplLVP3DZ1UolhoaoCArKEXB48ePV40aNVS8eHF7a9iwoWbOnOmV6OjevbtKlSqlokWLql27dkpOTvY6x7Zt29S6dWsVKVJEsbGx6tevnzIzM/0b0DzzzDOqVq2aUlJStH79ehUrVkyNGjWyO+OL/v3728HPyVtQcDEVZPv27bcvcGxcaa/22NgY7Une61q/TMd1PT9XDe2iUjfX0fJ2Lypt935Pe+HL4lSuy61a12ucDs5fbdfZbH39Mx1Z8ZsuebilfUyJJtVU6ua6WvOvN3R4yXqlrtqijc++q6wT6Yq/90YXf6qCj/vWf7i2ZilXrpyGDx9uj9wsXbpUzZo105133qmkpCR7f+/evfXVV19p2rRp+vHHH7Vr1y7dddddns9nZWXZwUx6eroWLFigyZMnKyEhQQMHDvRvQGN9Myu7Urp0aVWsWNHuZMuWLdWkSRNt3pz3Mffw8HBPNJe7FeThJktGRoaWLVupZjc19rRZfbbeL1qU6GrfTMZ1Pb9gpvRt12pFuxd1YluK176Q3NlO2d4VfjlZ2VLwn//Zh0Sc/hj7fXDB/u/Rbdy3/sO1NauG5o477tBtt92mq666SldffbVefvllOxOzaNEiO1nx3nvvaeTIkXagU7duXU2aNMmOJaz9lu+++05r1qzRRx99pFq1aunWW2/V4MGDNXbsWDvI8VtAY9XPWGObJ99kVrrJ+oGs4SdrSCqQjRo9UY90eUAdO7ZX5coVNfat4YqMjFDC5Klud81oXFffWUNFcXc30Zpuo5WVesKeZm1twYUL2futYt9jm3fr6lcfVbHaFf/M2Dx2u0reUEP7Zi62jzm8dINdRFz5ze6KrHqZvSbNFQM7qnD5WP0xe5nLP2HBx33rP1xbd6Wlpenw4cNe26l1r6djZVs++eQTHT161B56srI2VoDaokULzzGVK1dW+fLltXDhQvu99WqVsMTFxXmOsRIl1vfMzfL4pSjY6oiVUrLqaE721ltv2a9t2rRRIJs27UvFlI7WCwP7Kj4+RitWJKn17Q8qJcW7eA2+4br6LnfYqPYXL3q1r3tirD2dOyczS6seGKorBnRQ9Q+fUUhkYXta9rqeY7V/zq+eWU7W9O8K/e9Xrf8MUlBYiI6u36HVnV6xh6hwdty3/sO1/Xv+nF09bNgwvfii9++WQYMG6YUXXjjt8atWrbIDGKtexsrOTJ8+3Z40tHz5chUqVEglSnjX5FnBy549f05OsF5PDmZy9+fu80VQjjW9yIcfcv78+frmm29Ou//xxx/XhAkTlJ2dLV+FFrrE588Abvq+5PVudyFgtTiwwO0uAD7LTN+Zb99rUdm/6lAutNpb/s+RkbFKRaztdKyhIauW1hpi+uyzz/Tuu+/a9TJWQGNNFDr1XNdee61uuukmvfLKK3r00Ue1detWzZo1y7P/2LFjioyMtGMNawjKL0NOVjHvmYIZy7hx484pmAEAAAWjhib8NHWuZwpmLFYWxqqrtWpkrMRHzZo1NXr0aMXHx9vBzsGDB72Ot2Y5Wfss1uups55y3+cek1csrAcAgGEKyrTt07ESG1ZWxgpwrIUS58yZ49lnzZC2sjnWEJXFerWGrKzZ07lmz55tB1GnrnV3wRfWAwAAyB25sYaFrELfI0eOaMqUKfrhhx/sISRrjbkuXbqoT58+9mK8VpDSs2dPO4hp0KCB/flbbrnFDlw6duyoESNG2HUzAwYMsNeuOVtW6HQIaAAAMExBKe5ISUmxnw5gLbJrBTDWIntWMHPzzTfb+0eNGqXg4GB7QT0ra2PNYLLKU3KFhIRoxowZ6tatmx3oWLUznTp10ksvveRzX3wqCvYnioJhGoqC/YeiYJgoP4uC58ff7bdzN9nzmUxEhgYAAMPkiMUvT0VRMAAAMB4ZGgAADHPqE0tAhgYAAAQAMjQAABgmmxoaBzI0AADAeGRoAAAwDLOcnAhoAAAwTEFZWK8gYcgJAAAYjwwNAACGYcjJiQwNAAAwHhkaAAAMQw2NExkaAABgPDI0AAAYhgyNExkaAABgPDI0AAAYhllOTgQ0AAAYJpt4xoEhJwAAYDwyNAAAGIanbTuRoQEAAMYjQwMAgGFy3O5AAUSGBgAAGI8MDQAAhmFhPScyNAAAwHhkaAAAMEx2ELOcTkVAAwCAYSgKdmLICQAAGI8MDQAAhqEo2IkMDQAAMB4ZGgAADMPDKZ3I0AAAAOORoQEAwDA8nNKJDA0AADAeGRoAAAzDOjROBDQAABiGomAnApqLQDBLZPtFiwML3O5CwFp/dTW3uxCwKm1Y7XYXAL8goAEAwDAsrOdEUTAAADAeGRoAAAxDUbATGRoAAGA8MjQAABiGWU5OZGgAAIDxyNAAAGAYZjk5EdAAAGAYAhonhpwAAIDxyNAAAGCYHIqCHcjQAAAA45GhAQDAMNTQOJGhAQAAxiNDAwCAYcjQOJGhAQAAxiNDAwCAYXg4pRMBDQAAhuFZTk4MOQEAAOORoQEAwDAUBTuRoQEAAMYjQwMAgGHI0DiRoQEAAMYjQwMAgGGYtu1EhgYAABiPDA0AAIZhHRonAhoAAAxDUbATQ04AAMB4ZGgAADAMRcFOZGgAAIDxCGgAADBMtnL8tvli2LBhql+/vooVK6bY2Fi1bdtW69ev9zrmxIkT6t69u0qVKqWiRYuqXbt2Sk5O9jpm27Ztat26tYoUKWKfp1+/fsrMzPSpLwQ0AADgnPz44492sLJo0SLNnj1bGRkZuuWWW3T06FHPMb1799ZXX32ladOm2cfv2rVLd911l2d/VlaWHcykp6drwYIFmjx5shISEjRw4ECf+hKUk5NTIIbiQgtd4nYXAlZwEPP7/CG7YPynE5DWX13N7S4ErEobVrvdhYCVmb4z377X4Ms6+O3cz2/9+Jw/u3fvXjvDYgUuTZs21aFDhxQTE6MpU6bo7rvvto9Zt26dqlSpooULF6pBgwaaOXOmbr/9djvQiYuLs4+ZMGGCnnnmGft8hQoVytP3JkMDAAA80tLSdPjwYa/NassLK4CxREdH26+JiYl21qZFixaeYypXrqzy5cvbAY3Feq1evbonmLG0bNnS/r5JSUnKKwIaAAAMk+PHbdiwYYqKivLarLa/k52drV69eqlRo0aqVu3PLOuePXvsDEuJEiW8jrWCF2tf7jEnBzO5+3P35RXTtgEAMIw/F9br37+/+vTp49UWHh7+t5+zamlWr16tn376SW4goAEAAF7BS14CmJP16NFDM2bM0Lx581SuXDlPe3x8vF3se/DgQa8sjTXLydqXe8zixYu9zpc7Cyr3mLxgyAkAAAOf5eSvzRfWvCIrmJk+fbrmzp2rChUqeO2vW7euwsLCNGfOHE+bNa3bmqbdsGFD+731umrVKqWkpHiOsWZMFS9eXFWrVs1zX8jQAACAc2INM1kzmP773//aa9Hk1rxYdTcRERH2a5cuXewhLKtQ2ApSevbsaQcx1gwnizXN2wpcOnbsqBEjRtjnGDBggH1uXzJFBDQAABjG1wXw/GX8+PH264033ujVPmnSJHXu3Nn+etSoUQoODrYX1LNmS1kzmMaNG+c5NiQkxB6u6tatmx3oREZGqlOnTnrppZd86gvr0FwEWIfGP1iHxn9Yh8Z/WIcmMNahGXD5A34795Dfp8hE1ND4qNtjnbRpwyKlHv5NC376SvXr1XK7S8Z7fkAfpaft8NpWrfzB7W4FDO5Z3xS/93aV+3y8Kiz63N4u+WiUijSu59lfeuATKj9zkios/VKXz5uq+DEvKKzCpZ79xe68WVeunnXaLSQ6yqWfyjzct+5N2zYVQ04+aN++jV57dZAe7/6sFi/5VU/0fETffP2xqlZrqr17/3C7e0ZLSlqnVrfe73nv6zM8cHrcs77L3LNX+0e9r4ytO6WgIDtAiX/zBW2/u7syftuqtDUblfr1XGXu3qvgqGKKfvxBlXlnqLa17GQtxKHUb3/UsZ+Wep0z9uW+CgoPU9b+Pxcdw9lx3+JckKHxQe8nu+rd96Zo8gefau3ajfZ/bMeOHdfDne9zu2vGy8zMUnLyXs/2xx8H3O5SQOCe9d2xH3/RsflLlLFtlx3U7B+ToOxjJ1S4ZmV7/5HPZupE4mpl7kpW+tpN2v/mZIWViVXoJX8uBJaTlq6sPw54tpzsbEVcV1OHP5/l8k9mDu7bvK1D46/NVAQ0eWRNO6tTp4bmzJ3vabPKj+bM/UkNGtR1tW+BoGLFCvp9y1KtW/ezJie8qUsvLet2l4zHPXsBBAer6K03KDgiXCeWr3XsDooIV7G2tyhj+247Y3M6xdq0UPbxNB397q//P+DMuG9xrhhyyqPSpaMVGhqqlOR9Xu0pKXtVudKVrvUrEFgp5Uce6a0NGzYrvkysBjzXW3PnfK7adZorNfWvJ7bCN9yz567QVZfrko/fUFChQso+dlx7nnxJGZu3edXZlHrqEQUXiVD65u3a9Wh/K8142nMVv6ulUr/5n525wd/jvjVrlpPRAc3atWvtx4RbU6usB0xZT80cPXq0PRXrwQcfVLNmzf72HNaxpz7oyorAg5iNc1GaNet/nq9XrV6rxYt/1aaNi3T33XcoIeETV/uGi1P6lh3a3u5xBRcroqK3NLFrYHZ27ucJaqwamuMLlykkJlolOt+t+Nee086OvZWTnuF1nvCaVVToysuU3H+ESz8JAhXhzHkOOX377beqVauW+vbtq9q1a9vvrceDb9q0SVu3brUXx7FWCvw7p3vwVU72ERVk+/bttwtVY+NKe7XHxsZoT/LpU804N4cOHdbGjZtV8crL3e6K0bhnz0NmpjK371L6mk3a/8Ykpa3foqgH23p2Z6ces2tsrFqaPb2H2LOcIps3cpymeLtWSlu7yT4P8ob7FvkS0FiL3PTr109//PGHvWjOAw88oK5du9pLFFvLGlv7hg8fnqcHX1mPGD95CwoupoLMevz5smUr1eymxp42K6NkvV+0KNHVvgWayMgiuuKKy7V7z1/LYMN33LMXTlBwkIIKhZ1hZ5Bk/e8p+4MiCqtoy6YUA/uI+zZvKAo+zyGnpKQkffDBB/bX99xzj71M8d133+3Z36FDBzvQOZcHX5kw3DRq9ERNem+UEpet1BJ7KmFXRUZGKGHyVLe7ZrThwwfo66+/17ZtO1SmTJwGDnxKWVlZmjr1C7e7ZjzuWd9F93rYnuVkT8uOjFDR1jepcP0aOvCv5xRaLl5FW92gYwsSlb3/kELiY1Syyz12fcyx+d4P17OKiRUSotQZfz3DBnnDfYt8qaHJDTysZYwLFy5sDxflsp7jYGVbAtW0aV8qpnS0XhjYV/HxMVqxIkmtb39QKSnexWvwTblLyujDD95SqVIltXfvfi1YsFhNmraxU884P9yzvguJLqHYof0UGhOt7CPHlLZhi3b/6zlPzUzhOtUU1fEfCileVFl/HNTxpau088HejjVmit/VSke//1nZRyhs9xX37d+jKPg8H31Qs2ZNvfLKK2rVqpX9fvXq1XZhsFWRbpk/f779/IXNmzfLVzz6wH949IF/8OgD/+HRB/7Dow8C49EHfS7335o8I3//JPAzNNaDo6yhgFzVqnn/0pk5c2aeZjkBAIBzx59T5xnQPPbYY2fdP3ToUF9OBwAAcEGwsB4AAIYxeTaSvxDQAABgmBwGnRx4lhMAADAeGRoAAAzDkJMTGRoAAGA8MjQAABiGhfWcyNAAAADjkaEBAMAw5GecyNAAAADjkaEBAMAw1NA4EdAAAGAYpm07MeQEAACMR4YGAADD8OgDJzI0AADAeGRoAAAwDDU0TmRoAACA8cjQAABgGGponMjQAAAA45GhAQDAMNTQOBHQAABgmOwchpxOxZATAAAwHhkaAAAMQ37GiQwNAAAwHhkaAAAMw9O2ncjQAAAA45GhAQDAMCys50SGBgAAGI8MDQAAhmFhPScCGgAADENRsBNDTgAAwHhkaAAAMAxFwU5kaAAAgPHI0AAAYBiKgp3I0AAAAOORoQEAwDA5OdTQnIoMDQAAMB4ZGgAADMM6NE4ENAAAGIaiYCeGnAAAgPHI0FwEsikeg2EqbVjtdhcC1qySjd3uAi4AFtZzIkMDAACMR4YGAADDUBTsRIYGAAAYjwwNAACGYWE9JzI0AADAeGRoAAAwDOvQOBHQAABgGKZtOzHkBAAAjEeGBgAAwzBt24kMDQAAMB4ZGgAADMO0bScyNAAAwHgENAAAGFhD46/NF/PmzdMdd9yhsmXLKigoSF988YUjkzRw4ECVKVNGERERatGihTZu3Oh1zP79+9WhQwcVL15cJUqUUJcuXZSamipfEdAAAIBzcvToUdWsWVNjx4497f4RI0ZozJgxmjBhgn755RdFRkaqZcuWOnHihOcYK5hJSkrS7NmzNWPGDDtIevTRR33uS1BOARmICy10idtdAICAN6tkY7e7ELCaJ0/Nt+91Y7kWfjv3Dzu+P6fPWRma6dOnq23btvZ7K7ywMjdPPfWU+vbta7cdOnRIcXFxSkhI0H333ae1a9eqatWqWrJkierVq2cf8+233+q2227Tjh077M/nFRkaAAAMk52T47ctLS1Nhw8f9tqsNl9t2bJFe/bssYeZckVFRem6667TwoUL7ffWqzXMlBvMWKzjg4OD7YyOLwhoAACAx7Bhw+zA4+TNavOVFcxYrIzMyaz3ufus19jYWK/9oaGhio6O9hyTV0zbBgDAMP6sFenfv7/69Onj1RYeHq6CjoAGAAB4BS8XIoCJj4+3X5OTk+1ZTrms97Vq1fIck5KS4vW5zMxMe+ZT7ufziiEnAAAMU1CmbZ9NhQoV7KBkzpw5njarHseqjWnYsKH93no9ePCgEhMTPcfMnTtX2dnZdq2NL8jQAACAc2KtF7Np0yavQuDly5fbNTDly5dXr169NGTIEF111VV2gPP888/bM5dyZ0JVqVJFrVq1UteuXe2p3RkZGerRo4c9A8qXGU4WAhoAAAxTUB5OuXTpUt10002e97m1N506dbKnZj/99NP2WjXWujJWJqZx48b2tOzChQt7PvPxxx/bQUzz5s3t2U3t2rWz167xFevQAMBFhHVoAmMdmoaX/BVEXGgLd/5PJiJDAwCAYQpILqJAoSgYAAAYjwwNAACGKSg1NAUJAQ0AAIbJIaBxYMgJAAAYjwwNAACGoSjYiQwNAAAwHhkaAAAMQ1GwExkaAABgPDI0AAAYhhoaJzI0AADAeGRoAAAwDDU0TgQ0AAAYhoX1nBhyAgAAxiNDAwCAYbIpCnYgQwMAAIxHhgYAAMNQQ+NEhiaPnnm6hxYu+FoH/livXTtW6D+fvaerr77S7W4FjG6PddKmDYuUevg3LfjpK9WvV8vtLgWEJo2v0xfTE7Tt90Rlpu9UmzYt3e5SQOG+9c1lT7RV/W+H6obfEtQk6R3VSOirIleW8TqmUEyUqr7VXY1Xva0bt0xW/dnDFdP6Ws/+wpfGqMqof+n6JW/qxt8/VMNfRqtCv/YKCgtx4SdCQUJAk0dNmzTQ+PGT1ajJHWp12/0KCw3TzK+nqEiRCLe7Zrz27dvotVcHafCQkap/XSutWLlG33z9sWJiSrndNeNFRhbRypVr1PPJ59zuSsDhvvVdyYZVtGPSLC29bYB+bf+ygkJDVGvqcwouEu45xgpmilQsq5UPjdCiG/tp7zeLVX1ibxWtdrm939qnoGCt6ztRi254ShsHfqBynVroyn/fr4uthsZfm6mCci7AcoPWKYKCgs7rHKGFLpFJSpeO1p5dq3RTs7s0/6df3O6O0ay/bJcsXaEnew2w31v30u+bl2jsuEka8epYt7sXMKwMzV13/1NffjnL7a4EBFPv21klG6ugCCtVTE3XvKvEO1/QwUVr7bYbNk/W+qff1Z7P5nuOa7r2XW0aMkW7Pp572vOUf/wOlet8sxZc+4Tc1Dx5ar59ryqxf2WtLrS1KYt10WZowsPDtXbtnzfjxSIqqrj9uv/AQbe7YrSwsDDVqVNDc+bO9wqQ58z9SQ0a1HW1b8CZcN9eGKHFitivGQdTPW2HlqxXXNuGCi0RaUWJimt7vYILh+nAz0lnPk/xIso48Nc5LpYaGn/9z0VRFNynT5/TtmdlZWn48OEqVerPVOvIkSPPep60tDR7u9BZnvxi9XPkay/q558XKylpvdvdMZqV6QoNDVVK8j6v9pSUvapciRolFEzctxdAUJCuHtJJB39Zp6PrtnuaV3d9Q9Xe6aUb1r+v7IxMZR9P18rOr+v478mnPU3E5XG6tEsrbXzxQ11MTB4aKhABzRtvvKGaNWuqRIkSjmDEytBERkbmKSgZNmyYXnzxRa+2oOCiCgr5M+tR0L05ZqiuuaaSbrjpH253BQCMVGn4PxVZ6VIlthnk1X7Fs/cqNKqIlt09WBl/HFHMrfVVbWIvJd45SEfX/hX4WMLjS6rWJ/9W8leLtOuj0w9H4eLhU0AzdOhQvfPOO3r99dfVrFkzr/RrQkKCqlatmqfz9O/f35HtKVmqskww+o0han1bC93U/C7t3Lnb7e4Yb9++/crMzFRsXGmv9tjYGO1J3utav4Cz4b49P1cPfVilb66jxLYvKG33fk97xGV/ZlsWNX1KR9fvsNtS12xViQaVVe7hlnZtTa5CcSVV5/OBOrRkg9Y99Y4uNiYPDRWIGppnn31WU6dOVbdu3dS3b19lZGScc81N8eLFvTYThpusYKbtna10c8t79Pvv3n8p4NxY99CyZSvV7Ka/ChWte8F6v2hRoqt9A86E+/b8gpmY267VsnaDdWKbd/AXXKSQ/ZqT7f2PdU5WtoKCg7wyM3WnD9ThlVu05slx1jBBPvUeAVUUXL9+fSUmJmrv3r2qV6+eVq9ebUQwciGGmTo8cJc6PtRDR46kKi4uxt4KFy7sdteMN2r0RD3S5QF17NhelStX1Ni3hisyMkIJk/NvxkAgT9uuWfMae7NUuLy8/fWll5Z1u2vG4771XaXhXRR/dxMldRujrNTj9poz1mYV/VqObdylY5t3q/KrXVW89pV2xqb8Y7cr+obq2jtziSeYqTN9kE7s/EObXvhQhUoV95znYsK07Qs8bfuTTz5Rr1697OBm1apVeR5yMnHatjXl9XT+2aW3Pvjw03zvT6B5vFtnPdWnm+LjY7RiRZJ69R6oxUt+dbtbxruhaUPN+f4zR/vkDz5Vl0d6u9KnQGLifevmtO0zTWte88Q47Z76o/11RIV4VRzwgEpcV0khkYV1bEuyto37yjONu8y9N6jqmMdPe545cffqYpm2fWXpOn4792/7lumiXIdmx44ddsamRYsWdlFwoAY0ABAICtI6NIEmPwOaK0rX9tu5N+8r2EG5357lVK5cOXsDAABwCw+nBADAMDk52W53ocAhoAEAwDDZTNt24OGUAADAeGRoAAAwzAV4rnTAIUMDAACMR4YGAADDUEPjRIYGAAAYjwwNAACGoYbGiQwNAAAwHhkaAAAMY/JDJP2FgAYAAMPkUBTswJATAAAwHhkaAAAMQ1GwExkaAABgPDI0AAAYhoX1nMjQAAAA45GhAQDAMNTQOJGhAQAAxiNDAwCAYVhYz4mABgAAwzDk5MSQEwAAMB4ZGgAADMO0bScyNAAAwHhkaAAAMAw1NE5kaAAAgPHI0AAAYBimbTuRoQEAAMYjQwMAgGFymOXkQEADAIBhGHJyYsgJAAAYjwwNAACGYdq2ExkaAABgPDI0AAAYhqJgJzI0AADAeGRoAAAwDDU0TmRoAACA8QhoAAAwMEPjr+1cjB07VpdffrkKFy6s6667TosXL1Z+I6ABAMAwOX7cfDV16lT16dNHgwYN0rJly1SzZk21bNlSKSkpyk8ENAAAwCMtLU2HDx/22qy2Mxk5cqS6du2qhx9+WFWrVtWECRNUpEgRvf/++8pXOfDJiRMncgYNGmS/4sLi2voP19Z/uLb+wXV1z6BBgxyJG6vtdNLS0nJCQkJypk+f7tX+0EMP5bRp0yYnPwVZ/yd/QyizWZFqVFSUDh06pOLFi7vdnYDCtfUfrq3/cG39g+vqnrS0NEdGJjw83N5OtWvXLl1yySVasGCBGjZs6Gl/+umn9eOPP+qXX35RfmHaNgAA+NvgpaCjhgYAAJyT0qVLKyQkRMnJyV7t1vv4+HjlJwIaAABwTgoVKqS6detqzpw5nrbs7Gz7/clDUPmBIScfWWk4a2qaiem4go5r6z9cW//h2voH19Ucffr0UadOnVSvXj1de+21euONN3T06FF71lN+oigYAACcl7feekuvvvqq9uzZo1q1amnMmDH2Anv5iYAGAAAYjxoaAABgPAIaAABgPAIaAABgPAIaAABgPAIaAx+RHmjmzZunO+64Q2XLllVQUJC++OILt7sUEIYNG6b69eurWLFiio2NVdu2bbV+/Xq3uxUQxo8frxo1athL8lubtd7GzJkz3e5WQBo+fLj9e6FXr15udwUFHAGNgY9IDzTWegXWtbSCRVw41nNUunfvrkWLFmn27NnKyMjQLbfcYl9vnJ9y5crZ/9AmJiZq6dKlatasme68804lJSW53bWAsmTJEr399tt28Aj8HaZt+8DKyFh/8Vrz7XNXQ7z00kvVs2dPPfvss253LyBYf4lNnz7dzibgwtq7d6+dqbECnaZNm7rdnYATHR1tr8PRpUsXt7sSEFJTU1WnTh2NGzdOQ4YMsdc2sRZsA86EDE0epaen23+NtWjRwtMWHBxsv1+4cKGrfQPywnpqce4/vLhwsrKy9Mknn9iZr/xe6j2QWdnF1q1be/3OBc6GRx/k0b59++xfXHFxcV7t1vt169a51i8gL6xsolWD0KhRI1WrVs3t7gSEVatW2QHMiRMnVLRoUTuzWLVqVbe7FRCsANEa1reGnIC8IqABLpK/dlevXq2ffvrJ7a4EjEqVKmn58uV25uuzzz6zn2VjDecR1Jyf7du368knn7TrvqzJF0BeEdAY+Ih0wBc9evTQjBkz7NlkVjErLtxThitWrGh/bT1t2MomjB492i5ixbmzhvatiRZW/UwuKztu3b9W/WJaWpr9uxg4FTU0Bj4iHcgLq97fCmasoZC5c+eqQoUKbncpoFm/D6x/bHF+mjdvbg/nWdmv3M16inOHDh3srwlmcCZkaAx8RHogzmbYtGmT5/2WLVvsX1xW8Wr58uVd7Zvpw0xTpkzRf//7X3stGuspuJaoqChFRES43T2j9e/fX7feeqt9fx45csS+zj/88INmzZrldteMZ92rp9Z5RUZGqlSpUtR/4awIaHxw77332lNfBw4c6HlE+rfffusoFIZvrHU8brrpJq/A0WIFjwkJCS72zPzF3yw33nijV/ukSZPUuXNnl3oVGKwhkYceeki7d++2A0RrnRQrmLn55pvd7hpw0WIdGgAAYDxqaAAAgPEIaAAAgPEIaAAAgPEIaAAAgPEIaAAAgPEIaAAAgPEIaAAAgPEIaAAAgPEIaAAAgPEIaAAAgPEIaAAAgEz3/wDXi7bDpgK0VwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 700x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.95       440\n",
      "           1       0.98      0.95      0.97       639\n",
      "           2       0.89      1.00      0.94       288\n",
      "           3       0.98      0.99      0.98       342\n",
      "           4       0.95      0.99      0.97       285\n",
      "\n",
      "    accuracy                           0.96      1994\n",
      "   macro avg       0.96      0.97      0.96      1994\n",
      "weighted avg       0.96      0.96      0.96      1994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "def print_confusion_matrix(y_true, y_pred, report=True):\n",
    "    labels = sorted(list(set(y_true)))\n",
    "    cmx_data = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    \n",
    "    df_cmx = pd.DataFrame(cmx_data, index=labels, columns=labels)\n",
    " \n",
    "    fig, ax = plt.subplots(figsize=(7, 6))\n",
    "    sns.heatmap(df_cmx, annot=True, fmt='g' ,square=False)\n",
    "    ax.set_ylim(len(set(y_true)), 0)\n",
    "    plt.show()\n",
    "    \n",
    "    if report:\n",
    "        print('Classification Report')\n",
    "        print(classification_report(y_test, y_pred))\n",
    "\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow-Lite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推論専用のモデルとして保存\n",
    "model.save(model_save_path, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\User\\AppData\\Local\\Temp\\tmpgp4fdu_e\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\User\\AppData\\Local\\Temp\\tmpgp4fdu_e\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\User\\AppData\\Local\\Temp\\tmpgp4fdu_e'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 42), dtype=tf.float32, name='input_layer_4')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 5), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2146075943760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2146021015248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2146075946752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2146021009616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2146021009264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2146076167504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6616"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルを変換(量子化)\n",
    "tflite_save_path = 'model/keypoint_classifier/keypoint_classifier.tflite'\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_quantized_model = converter.convert()\n",
    "\n",
    "open(tflite_save_path, 'wb').write(tflite_quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inference test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=tflite_save_path)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入出力テンソルを取得\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_details[0]['index'], np.array([X_test[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 推論実施\n",
    "interpreter.invoke()\n",
    "tflite_results = interpreter.get_tensor(output_details[0]['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3086917e-04 9.9695134e-01 6.5547179e-10 2.9178052e-03 9.6915649e-11]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(np.squeeze(tflite_results))\n",
    "print(np.argmax(np.squeeze(tflite_results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
